{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "#import python packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import *\n",
    "from sklearn.cluster import *\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from operator import itemgetter\n",
    "from operator import attrgetter\n",
    "\n",
    "from pyjarowinkler import distance\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#전처리 함수 정의부\n",
    "def remove_string_special_characters(s):\n",
    "    \n",
    "    stripped = re.sub('[^a-zA-z\\s]', '', s)\n",
    "    \n",
    "    stripped = re.sub('_', '', stripped)\n",
    "    \n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "    \n",
    "    stripped = stripped.strip()\n",
    "    \n",
    "    if stripped != '':\n",
    "        return stripped.lower()\n",
    "    \n",
    "#클래스 정렬 함수 정의부\n",
    "def multisort(xs, specs):\n",
    "    \n",
    "    for key, reverse in reversed(specs):\n",
    "        \n",
    "        xs.sort(key=attrgetter(key), reverse=reverse)\n",
    "        \n",
    "    return xs\n",
    "\n",
    "#속성집합 추출 함수 정의부\n",
    "#키워드 매개변수(입력csv path, 속선집합 포함 출력csv path, 추출할 단어 수)\n",
    "def extractive_keyword(path,database_update_path,extract_word_num=20):\n",
    "    \n",
    "    reviewee = pd.read_csv(path, encoding='latin1')\n",
    "    count,temp = len(reviewee),[]\n",
    "\n",
    "    for i in range(count):\n",
    "        \n",
    "        temp_intro = reviewee['submitter_intro'][i]\n",
    "#         temp_sent = summarize(reviewee['submitter_intro'][i], ratio=0.05)\n",
    "\n",
    "        textrank_textsent_mearge = ''\n",
    "        textrank_text,textrank_sent = '',''\n",
    "\n",
    "        for c in (keywords(temp_intro, words=extract_word_num, lemmatize=True).split('\\n')):\n",
    "            \n",
    "            textrank_text += (c+ \" \")\n",
    "\n",
    "#         for cc in (keywords(temp_sent, words=(extract_word_num//4), lemmatize=True).split('\\n')):\n",
    "            \n",
    "#             textrank_sent += (cc+ \" \")\n",
    "\n",
    "#         temp.append(textrank_text + \" \" + textrank_sent)\n",
    "        temp.append(textrank_text)\n",
    "\n",
    "    reviewee['submitter_attribute']=temp\n",
    "    \n",
    "    reviewee.iloc[:,1:].to_csv(database_update_path)\n",
    "    \n",
    "    #return type : pandas.dataframe\n",
    "    return reviewee\n",
    "\n",
    "\n",
    "#전문성 검사 함수 정의부\n",
    "#키워드 매개변수(입력csv path, 투고원고 DataFrame, i번째 투고 원고, 추천할 심사자 수, 실루엣값 계산 범위 지정)\n",
    "def professionalism(path,extractive_keyword_result,reviewee_index,top_limit,silhouette_range=25):\n",
    "    \n",
    "    reviewee=extractive_keyword_result\n",
    "    index=reviewee_index\n",
    "    top=top_limit\n",
    "    \n",
    "    temp_id,temp_doi = 0,''\n",
    "    \n",
    "    temp_title = reviewee.loc[index]['submitter_title']\n",
    "    temp_attribure = reviewee.loc[index]['submitter_attribute']\n",
    "\n",
    "    reviewer_attr = pd.read_csv(path, encoding='latin1')\n",
    "    \n",
    "    reviewer_attr.loc[-1]=[str(temp_id),temp_doi,temp_title,temp_attribure]\n",
    "    \n",
    "    reviewer_attr.index += 1\n",
    "    \n",
    "    reviewer_attr.sort_index(inplace=True)\n",
    "    \n",
    "    reviewer=reviewer_attr['reviewer_paper_attribure']\n",
    "    \n",
    "    jac_token,jac,cos,avg=[],[],[],[]\n",
    "\n",
    "    for t in range(len(reviewer)):\n",
    "        \n",
    "        jac_token.append(set(nltk.ngrams((nltk.word_tokenize(reviewer[t])), n=1)))\n",
    "        \n",
    "    for j in range(len(reviewer)):\n",
    "        \n",
    "        jac.append(1-(nltk.jaccard_distance(jac_token[0], jac_token[j])))\n",
    "\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    \n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    sparse_matrix = count_vectorizer.fit_transform(reviewer)\n",
    "    \n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                      columns=count_vectorizer.get_feature_names(), \n",
    "                      index=[i for i in reviewer])\n",
    "\n",
    "    cos=cosine_similarity(df, df)[0].tolist()\n",
    "\n",
    "    for i in range(len(jac)):\n",
    "        \n",
    "        avg.append((jac[i] + cos[i])/2)\n",
    "        \n",
    "    reviewer_attr['sim']=avg\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    Y = vectorizer.fit_transform(reviewer)\n",
    "    \n",
    "    YY = Y.toarray()\n",
    "    \n",
    "    X = StandardScaler().fit_transform(YY)\n",
    "\n",
    "    top_avg,top_k=0,0\n",
    "    silhouette,k_mean,k_mean2=[],[],[]\n",
    "\n",
    "    for i in range(2,silhouette_range+1,1):\n",
    "\n",
    "        model = SpectralClustering(n_clusters=i, affinity=\"nearest_neighbors\")\n",
    "        \n",
    "        cluster_labels = model.fit_predict(X)\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(YY, cluster_labels)\n",
    "        \n",
    "        silhouette_avg = sample_silhouette_values.mean()\n",
    "\n",
    "        if top_avg < silhouette_avg:\n",
    "            \n",
    "            top_avg = silhouette_avg\n",
    "            \n",
    "            top_k = i\n",
    "\n",
    "        silhouette_temp=[]\n",
    "        \n",
    "        silhouette_temp.append('k=' + str(i) + '일때 : ')\n",
    "        \n",
    "        silhouette_temp.append(silhouette_avg)\n",
    "        \n",
    "        silhouette.append(silhouette_temp)\n",
    "\n",
    "    model = KMeans(n_clusters=(top_k), init='k-means++', max_iter=100, n_init=1)\n",
    "    \n",
    "    model.fit(Y)\n",
    "    \n",
    "    for k in range(len(reviewer)):\n",
    "        \n",
    "        YYY = vectorizer.transform([reviewer[k]])\n",
    "        \n",
    "        prediction = model.predict(YYY)\n",
    "        \n",
    "        k_mean.append(prediction)\n",
    "\n",
    "    for k in range(len(reviewer)):\n",
    "        \n",
    "        k_mean2.append(int(k_mean[k][0]))\n",
    "        \n",
    "    reviewer_attr['k_mean']=k_mean2\n",
    "    \n",
    "    kmean_reviewer = reviewer_attr[reviewer_attr['k_mean'] == reviewer_attr.loc[0]['k_mean']]\n",
    "    \n",
    "    kmean_reviewer2 = kmean_reviewer.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    \n",
    "    professionalism=kmean_reviewer2.iloc[1:top+1]\n",
    "    \n",
    "    #return type : pandas.dataframe\n",
    "    return professionalism\n",
    "\n",
    "#이해관계 검사 함수 정의부\n",
    "#키워드 매개변수(심사후보자_공저자csv path, 심사후보자_정보csv path, 심사후보자_공저자네트워크csv path,전문성검사결과_DataFrame, 투고원고_DataFrame, i번째 투고 원고, 추천할 심사자 수, 심사후보자_공저자네트워크_곱셈횟수)\n",
    "def interest(co_author_path, reviewer_information_path, co_author_network_path, professionalism_result, extractive_keyword_result, reviewee_index,top_limit,matrix_multifly_count):\n",
    "    \n",
    "    crash_result,reviewee_list=[],[]\n",
    "    reviewer_list1,reviewer_co_list=[],[]\n",
    "    \n",
    "    path1=co_author_path\n",
    "    path2=reviewer_information_path\n",
    "    network_path=co_author_network_path\n",
    "    \n",
    "    temp = professionalism_result\n",
    "    reviewee=extractive_keyword_result\n",
    "    \n",
    "    index=reviewee_index\n",
    "    top=top_limit\n",
    "    multifly=matrix_multifly_count\n",
    "    \n",
    "    co_author_csv = pd.read_csv(path1, encoding='latin1')\n",
    "    \n",
    "    co_author_df = co_author_csv.merge(temp, on=['reviewer_orcid'])\n",
    "    \n",
    "    tt = co_author_df.iloc[:]['reviewer_name'].tolist()\n",
    "\n",
    "    reviewee_list=[]\n",
    "    reviewee.fillna(0, inplace=True)\n",
    "\n",
    "    for i in range(1,11):\n",
    "        col_index = (i*3)+5\n",
    "        if reviewee.loc[index][col_index] != 0:\n",
    "            reviewee_list.append(reviewee.loc[index][col_index])\n",
    "\n",
    "    reviewer_list,reviewer_co_list=[],[]\n",
    "\n",
    "    for j in range(len(co_author_csv)):\n",
    "\n",
    "        co_list_temp=[]\n",
    "        reviewer_list.append(co_author_csv['reviewer_name'][j])\n",
    "        co_list_temp.append(co_author_csv['reviewer_name'][j])\n",
    "\n",
    "        for i in range(1,11):\n",
    "            col_index = (i*2)\n",
    "            if co_author_csv.loc[j][col_index] != 0:\n",
    "                co_list_temp.append(co_author_csv.loc[j][col_index])\n",
    "\n",
    "        reviewer_co_list.append(co_list_temp)\n",
    "\n",
    "    co_rel_df = pd.DataFrame(\n",
    "        columns=[i for i in reviewer_list],\n",
    "        index=[j for j in reviewee_list])\n",
    "\n",
    "    for j in range(len(reviewee_list)):\n",
    "        for i in range(len(reviewer_list)):\n",
    "            for k in range(len(reviewer_co_list[i])):\n",
    "                if reviewee_list[j] == reviewer_co_list[i][k]:\n",
    "                    co_rel_df.iat[j, i] = 1\n",
    "\n",
    "    co_rel_df.fillna(0, inplace=True)\n",
    "    \n",
    "#     print(co_rel_df)\n",
    "#     co_rel_df.to_csv('./aaa.csv')\n",
    "\n",
    "    try :\n",
    "\n",
    "        matrix_df = pd.read_csv(co_author_network_path, encoding='latin1', index_col=0)\n",
    "\n",
    "    except FileNotFoundError :\n",
    "\n",
    "        index = co_author_csv['reviewer_orcid'].index[co_author_csv['reviewer_orcid'].apply(np.isnan)]\n",
    "\n",
    "        df_index = co_author_csv.index.values.tolist()\n",
    "\n",
    "        nan_range =[df_index.index(i) for i in index]\n",
    "\n",
    "        try :\n",
    "\n",
    "            import_csv2=co_author_csv.iloc[:nan_range[0]]\n",
    "            id_list=import_csv2['reviewer_name'].tolist()\n",
    "\n",
    "        except IndexError :\n",
    "\n",
    "            import_csv2=co_author_csv\n",
    "            id_list = co_author_csv.iloc[:]['reviewer_name'].tolist()\n",
    "\n",
    "        matrix_df = pd.DataFrame(\n",
    "\n",
    "            columns=[i for i in id_list],\n",
    "            index=[j for j in id_list])\n",
    "\n",
    "        for i in range(len(id_list)):\n",
    "\n",
    "            for j in range(len(id_list)):\n",
    "\n",
    "                index=[1,]\n",
    "\n",
    "                index.extend([(j*2) for j in range(1,11)])\n",
    "\n",
    "                for k in range(11):\n",
    "\n",
    "                    if (id_list[i]) == (import_csv2.iloc[j][index[k]]) :\n",
    "\n",
    "#                         print(id_list[i], import_csv2.iloc[j][index[k]])\n",
    "#                         print(i)\n",
    "\n",
    "                        matrix_df.iat[j, i] = 1\n",
    "                        matrix_df.iat[i, j] = 1\n",
    "\n",
    "                if str(id_list[i]) == str(id_list[j]):\n",
    "\n",
    "                    matrix_df.iat[i, j] = 0\n",
    "\n",
    "        matrix_df.fillna(0, inplace=True)\n",
    "        matrix_df.to_csv(co_author_network_path)\n",
    "    \n",
    "    for i in range(multifly):\n",
    "        \n",
    "        matrix_df = matrix_df.dot(matrix_df)\n",
    "\n",
    "    a=matrix_df.values\n",
    "    b=co_rel_df.values\n",
    "    \n",
    "    aaa = b.dot(a)\n",
    "\n",
    "    aaa2=pd.DataFrame(data=aaa,\n",
    "                 index=(co_rel_df.index).tolist(),\n",
    "                 columns=(matrix_df.index).tolist())\n",
    "\n",
    "    a_series = (aaa2 != 0).any(axis=1)\n",
    "    \n",
    "    new_df = aaa2.loc[a_series]\n",
    "    \n",
    "    ccc=(new_df.index).tolist()\n",
    "    \n",
    "    ddd=co_author_df['reviewer_name'].tolist()\n",
    "    \n",
    "    reviewer_list1 = list(set(ddd).difference(ccc))\n",
    "    \n",
    "    co_inst_csv = pd.read_csv(path2, encoding='latin1')\n",
    "    \n",
    "    co_inst_df = co_inst_csv.merge(temp, on=['reviewer_orcid'])\n",
    "\n",
    "    reviewee_list2,reviewer_list2,reviewer_inst_list=[],[],[]\n",
    "    \n",
    "    reviewee.fillna(0, inplace=True)\n",
    "\n",
    "    for i in range(1,11):\n",
    "        \n",
    "        col_index = (i*3)+6\n",
    "        \n",
    "        if reviewee.loc[index][col_index] != 0:\n",
    "            \n",
    "            reviewee_list2.append(reviewee.loc[index][col_index])\n",
    "\n",
    "    for j in range(len(co_inst_df)):\n",
    "        \n",
    "        inst_list_temp=[]\n",
    "        \n",
    "        reviewer_list2.append(co_inst_df['reviewer_name'][j])\n",
    "        \n",
    "        reviewer_inst_list.append(co_inst_df['reviewer_institution'][j])\n",
    "\n",
    "    inst_rel_df = pd.DataFrame(\n",
    "        columns=[i for i in reviewee_list2],\n",
    "        index=[j for j in reviewer_list2])\n",
    "\n",
    "    for i in range(len(reviewee_list2)):\n",
    "        \n",
    "        for j in range(len(reviewer_list2)):\n",
    "            \n",
    "            if reviewee_list2[i] == reviewer_inst_list[j]:\n",
    "                \n",
    "                inst_rel_df.iat[j, i] = 1\n",
    "\n",
    "    for i in range(len(reviewer_list2)):\n",
    "        \n",
    "        if (inst_rel_df.sum(axis=1)[i]) > 0:\n",
    "            \n",
    "            reviewer_list2.remove(inst_rel_df.index[i])\n",
    "            \n",
    "            crash_result.append(inst_rel_df.index[i])\n",
    "\n",
    "    reviewer_list1,reviewer_list2 = reviewer_list1[0:top*2],reviewer_list2[0:top*2]\n",
    "    \n",
    "    reviewer_rank = list(set(reviewer_list1).intersection(reviewer_list2))\n",
    "    \n",
    "    id_index,sim_index,count_index=[],[],[]\n",
    "    \n",
    "    reviewer_rank = pd.DataFrame({'reviewer_name': reviewer_rank})\n",
    "\n",
    "    for i in range(len(reviewer_rank)):\n",
    "        \n",
    "        for j in range(len(co_author_df)):\n",
    "            \n",
    "            if reviewer_rank.loc[i]['reviewer_name'] == co_author_df.loc[j]['reviewer_name'] :\n",
    "                \n",
    "                id_index.append(int(co_author_df.iloc[j]['reviewer_orcid']))\n",
    "                \n",
    "                sim_index.append(co_author_df.iloc[j]['sim'])\n",
    "            \n",
    "            if reviewer_rank.loc[i]['reviewer_name'] == co_inst_df.loc[j]['reviewer_name'] :\n",
    "                \n",
    "                count_index.append(co_inst_df.iloc[j]['count'])\n",
    "                \n",
    "    reviewer_rank['reviewer_orcid']=id_index\n",
    "    \n",
    "    reviewer_rank['sim']=sim_index\n",
    "    \n",
    "    reviewer_rank['count']=count_index\n",
    "                \n",
    "    #return type : pandas.dataframe\n",
    "    return reviewer_rank\n",
    "\n",
    "\n",
    "#csv 저장 함수 정의부\n",
    "#키워드 매개변수(save_path, 투고원고_DataFrame, 전문성검사_DataFrame, i번째 투고 원고, 추천할 심사자 수)\n",
    "def save_csv(output_path,extractive_keyword_result,professionalism_result,reviewee_index,top_limit):\n",
    "    \n",
    "    path=output_path\n",
    "    \n",
    "    reviewee=extractive_keyword_result\n",
    "    \n",
    "    reviewer_rank_name=professionalism_result\n",
    "    \n",
    "    ee_num=reviewee_index\n",
    "    \n",
    "    top=top_limit\n",
    "    \n",
    "    export_data=[]\n",
    "\n",
    "    for i in range((top*2)):\n",
    "        \n",
    "        temp=[]\n",
    "        \n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['submitter_title'])\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['date'])\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['submitter_name'])\n",
    "        \n",
    "        temp.append(reviewer_rank_name.iloc[i]['reviewer_name'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['reviewer_orcid'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['sim'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['count'])\n",
    "        \n",
    "        export_data.append(temp)\n",
    "        \n",
    "    try :\n",
    "            \n",
    "        export_csv = pd.read_csv(path,index_col=0)\n",
    "        \n",
    "    except FileNotFoundError :\n",
    "            \n",
    "        export_csv = pd.DataFrame([],columns=[\n",
    "            'submitter_title','date','submitter_name','reviewer_name','reviewer_orcid','sim','count'])\n",
    "    \n",
    "    for i in range(len(export_data)):\n",
    "        \n",
    "        export_csv.loc[len(export_csv)] = export_data[i]\n",
    "        \n",
    "    export_csv.to_csv(path)\n",
    "\n",
    "#균등할당 함수 정의부\n",
    "#키워드 매개변수(입력 path)\n",
    "def equl_distribution(input_csv_path, output_csv_path):\n",
    "    \n",
    "    final_list=[]\n",
    "    \n",
    "    export_csv2 = pd.read_csv(input_csv_path,index_col=0)\n",
    "\n",
    "    class Paper:\n",
    "        \n",
    "        def __init__(self, title, date, submitter, reviwer_name, reviwer_orcid, sim, count):\n",
    "            \n",
    "            self.title = title\n",
    "            self.date = date\n",
    "            self.submitter = submitter\n",
    "            self.reviwer_name = reviwer_name\n",
    "            self.reviwer_orcid = reviwer_orcid\n",
    "            self.sim = sim\n",
    "            self.count = count\n",
    "\n",
    "        def __repr__(self):\n",
    "            \n",
    "            return repr((self.title, self.date, self.submitter, self.reviwer_name, self.reviwer_orcid, self.sim, self.count))\n",
    "\n",
    "    papers,objs=[export_csv2.iloc[i].tolist() for i in range(len(export_csv2))],[]\n",
    "\n",
    "    for paper in papers:\n",
    "        \n",
    "        objs.append(Paper(*paper))\n",
    "    \n",
    "    o = (multisort(list(objs), (('date', False), ('sim', True))))\n",
    "\n",
    "    for i in range(0,len(export_csv2),6) :\n",
    "        \n",
    "        temp_list=[]\n",
    "        \n",
    "        for t in range(6):\n",
    "            \n",
    "            if len(temp_list) == 3:\n",
    "                break\n",
    "            else :\n",
    "                temp = i + t\n",
    "\n",
    "                if (o[temp].count) < 3 :\n",
    "\n",
    "                    o[temp].count += 1\n",
    "\n",
    "                    for j in range(0+temp, len(export_csv2)) :\n",
    "\n",
    "                        if (o[temp].reviwer_name == o[j].reviwer_name) :\n",
    "\n",
    "                            o[j].count += 1\n",
    "\n",
    "                    o[temp].count -= 1\n",
    "                    \n",
    "                    temp_list.append(o[temp])\n",
    "                    \n",
    "        final_list.extend(temp_list)\n",
    "            \n",
    "    final=pd.DataFrame(final_list,columns=['result'])\n",
    "    \n",
    "    final.to_csv(output_csv_path)\n",
    "\n",
    "#디폴트 실행 함수 정의부\n",
    "def main():\n",
    "    \n",
    "    #투고원고에 대한 속성집합 추출\n",
    "    #키워드 매개변수(입력csv path, 속선집합 포함 출력csv path, 추출할 단어 수)\n",
    "    reviewee=extractive_keyword(path='../reviewee/submitter_100.csv',\n",
    "                                database_update_path='../reviewee/sybmitter_update100.csv',\n",
    "                                extract_word_num=20)\n",
    "    #return type : pandas.dataframe\n",
    "    \n",
    "    \n",
    "    #투고원고 수 만큼의 검사세트 진행\n",
    "    for i in range(len(reviewee)):\n",
    "        \n",
    "        #전문성검사\n",
    "        #키워드 매개변수(입력csv path, 투고원고 DataFrame, i번째 투고 원고, 추천할 심사자 수, 실루엣값 계산 범위 지정)\n",
    "        reviewer=professionalism(path='../reviewer_pool/100/reviewer_attribute_6.csv',\n",
    "                                 extractive_keyword_result=reviewee,\n",
    "                                 reviewee_index=i,\n",
    "                                 top_limit=10,\n",
    "                                 silhouette_range=25)\n",
    "        #return type : pandas.dataframe\n",
    "        \n",
    "        \n",
    "        #이해관계검사\n",
    "        #키워드 매개변수(심사후보자_공저자csv path, 심사후보자_정보csv path, 심사후보자_공저자네트워크csv path,\n",
    "        #전문성검사결과_DataFrame, 투고원고_DataFrame, i번째 투고 원고, 추천할 심사자 수, 심사후보자_공저자네트워크_곱셈횟수)\n",
    "        reviewer_rank = interest(\n",
    "            co_author_path='../reviewer_pool/100/reviewer_coauthor_6.csv',\n",
    "            reviewer_information_path='../reviewer_pool/100/reviewer_information_6.csv',\n",
    "            co_author_network_path='../reviewer_pool/100/co_author_network_0530.csv',\n",
    "            professionalism_result=reviewer,\n",
    "            extractive_keyword_result=reviewee,\n",
    "            reviewee_index=i,\n",
    "            top_limit=6,\n",
    "            matrix_multifly_count=1)\n",
    "        #return type : pandas.dataframe\n",
    "        \n",
    "        \n",
    "        #csv저장\n",
    "        #키워드 매개변수(save_path, 투고원고_DataFrame, 전문성검사_DataFrame, i번째 투고 원고, 추천할 심사자 수)\n",
    "        save_csv(output_path='../algorithm_output/100/export_csv_0530_100.csv',\n",
    "                 extractive_keyword_result=reviewee,\n",
    "                 professionalism_result=reviewer_rank,\n",
    "                 reviewee_index=i,\n",
    "                 top_limit=3)\n",
    "        \n",
    "    #균등할당\n",
    "    #키워드 매개변수(입력 path)\n",
    "    equl_distribution(input_csv_path='../algorithm_output/100/export_csv_0530_100.csv',\n",
    "                     output_csv_path='../algorithm_output/100/final_csv_0530_100.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
